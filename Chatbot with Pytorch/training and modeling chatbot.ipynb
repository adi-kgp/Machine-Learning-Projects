{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"mount_file_id":"12pKVYVXK7f4PILUseXCmPOMbno50AjME","authorship_tag":"ABX9TyNFGrxhuMvmNKruJLAz+088"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# utility functions for processing Natural Language Texts\n","import nltk\n","import numpy as np\n","nltk.download('punkt')\n","from nltk.stem.porter import PorterStemmer\n","stemmer = PorterStemmer()\n","\n","def tokenize(sentence):\n","    return nltk.word_tokenize(sentence)\n","\n","def stem(word):\n","    return stemmer.stem(word.lower())\n","\n","def bag_of_words(tokenized_sentence, all_words):\n","    \"\"\"\n","    sentence = ['hello', 'how', 'are', 'you']\n","    words = ['hi', 'hello', 'I', 'you', 'bye', 'thank', 'cool']\n","    bog = [0, 1, 0, 1, 0, 0, 0]\n","    \"\"\"\n","    tokenized_sentence = [stem(w) for w in tokenized_sentence]\n","    bag = np.zeros(len(all_words), dtype=np.float32)\n","    for idx, w in enumerate(all_words):\n","        if w in tokenized_sentence:\n","            bag[idx] = 1.0\n","    return bag"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Fh_uNEUvx8J","executionInfo":{"status":"ok","timestamp":1665842404793,"user_tz":-330,"elapsed":1064,"user":{"displayName":"Aditya Sharma","userId":"18274581938771633663"}},"outputId":"e9dc7204-5078-452f-ee27-fd580ee5dcaa"},"execution_count":104,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}]},{"cell_type":"code","source":["import torch \n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader"],"metadata":{"id":"u1ZdhdHtR_Gv","executionInfo":{"status":"ok","timestamp":1665842406624,"user_tz":-330,"elapsed":122,"user":{"displayName":"Aditya Sharma","userId":"18274581938771633663"}}},"execution_count":105,"outputs":[]},{"cell_type":"code","execution_count":106,"metadata":{"id":"WajsxcOIMxg0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665842406625,"user_tz":-330,"elapsed":117,"user":{"displayName":"Aditya Sharma","userId":"18274581938771633663"}},"outputId":"eee3a616-3b17-4288-f20f-c733117bcbd4"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'intents': [{'tag': 'greeting', 'patterns': ['Hi', 'Hey', 'How are you', 'Is anyone there?', 'Hello', 'Good day'], 'responses': ['Hey :-)', 'Hello, thanks for visiting', 'Hi there, what can I do for you?', 'Hi there, how can I help?']}, {'tag': 'goodbye', 'patterns': ['Bye', 'See you later', 'Goodbye'], 'responses': ['See you later, thanks for visiting', 'Have a nice day', 'Bye! Come back again soon.']}, {'tag': 'thanks', 'patterns': ['Thanks', 'Thank you', \"That's helpful\", \"Thank's a lot!\"], 'responses': ['Happy to help!', 'Any time!', 'My pleasure']}, {'tag': 'items', 'patterns': ['Which items do you have?', 'What kinds of items are there?', 'What do you sell?'], 'responses': ['We sell coffee and tea', 'We have coffee and tea']}, {'tag': 'payments', 'patterns': ['Do you take credit cards?', 'Do you accept Mastercard?', 'Can I pay with Paypal?', 'Are you cash only?'], 'responses': ['We accept VISA, Mastercard and Paypal', 'We accept most major credit cards, and Paypal']}, {'tag': 'delivery', 'patterns': ['How long does delivery take?', 'How long does shipping take?', 'When do I get my delivery?'], 'responses': ['Delivery takes 2-4 days', 'Shipping takes 2-4 days']}, {'tag': 'funny', 'patterns': ['Tell me a joke!', 'Tell me something funny!', 'Do you know a joke?'], 'responses': ['Why did the hipster burn his mouth? He drank the coffee before it was cool.', 'What did the buffalo say when his son left for college? Bison.']}]}\n"]}],"source":["import json\n","\n","with open('/content/drive/MyDrive/Data Science WorkSpace/Machine Learning Projects/Chatbot with Pytorch/intents.json', 'r') as f:\n","    intents = json.load(f)\n","\n","print(intents)"]},{"cell_type":"code","source":["all_words = []\n","tags = []\n","xy = []\n","\n","for intent in intents['intents']:\n","    tag = intent['tag']\n","    tags.append(tag)\n","    for pattern in intent['patterns']:\n","        w = tokenize(pattern)\n","        all_words.extend(w)\n","        xy.append((w, tag))\n","\n","ignore_words = ['?', '!', '.', ','] \n","all_words = [stem(w) for w in all_words if w not in ignore_words]\n","print(all_words)"],"metadata":{"id":"SHdTLH0_TizI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665842406628,"user_tz":-330,"elapsed":105,"user":{"displayName":"Aditya Sharma","userId":"18274581938771633663"}},"outputId":"789206e7-153c-4096-825b-161da95bf269"},"execution_count":107,"outputs":[{"output_type":"stream","name":"stdout","text":["['hi', 'hey', 'how', 'are', 'you', 'is', 'anyon', 'there', 'hello', 'good', 'day', 'bye', 'see', 'you', 'later', 'goodby', 'thank', 'thank', 'you', 'that', \"'s\", 'help', 'thank', \"'s\", 'a', 'lot', 'which', 'item', 'do', 'you', 'have', 'what', 'kind', 'of', 'item', 'are', 'there', 'what', 'do', 'you', 'sell', 'do', 'you', 'take', 'credit', 'card', 'do', 'you', 'accept', 'mastercard', 'can', 'i', 'pay', 'with', 'paypal', 'are', 'you', 'cash', 'onli', 'how', 'long', 'doe', 'deliveri', 'take', 'how', 'long', 'doe', 'ship', 'take', 'when', 'do', 'i', 'get', 'my', 'deliveri', 'tell', 'me', 'a', 'joke', 'tell', 'me', 'someth', 'funni', 'do', 'you', 'know', 'a', 'joke']\n"]}]},{"cell_type":"code","source":["all_words = sorted(set(all_words))\n","tags = sorted(set(tags))\n","print(tags)"],"metadata":{"id":"M0P9sFoYF7Nk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1665842406629,"user_tz":-330,"elapsed":94,"user":{"displayName":"Aditya Sharma","userId":"18274581938771633663"}},"outputId":"3150b4a9-dc9b-4e72-a251-9bf67500b6ee"},"execution_count":108,"outputs":[{"output_type":"stream","name":"stdout","text":["['delivery', 'funny', 'goodbye', 'greeting', 'items', 'payments', 'thanks']\n"]}]},{"cell_type":"markdown","source":["### Modeling the chatbot"],"metadata":{"id":"3Vrf4_B_VdWA"}},{"cell_type":"code","source":["X_train = []\n","y_train = []\n","import numpy as np\n","\n","for (pattern_sentence, tag) in xy:\n","    #X: bag of words for each pattern_sentence\n","    bag = bag_of_words(pattern_sentence, all_words)\n","    X_train.append(bag)\n","    # y: PyTorch CrossEntropyLoss needs only class labels, not one-hot\n","    label = tags.index(tag)\n","    y_train.append(label)  \n","\n","X_train = np.array(X_train)\n","y_train = np.array(y_train)"],"metadata":{"id":"OJXjAm8LMQSk","executionInfo":{"status":"ok","timestamp":1665842406631,"user_tz":-330,"elapsed":80,"user":{"displayName":"Aditya Sharma","userId":"18274581938771633663"}}},"execution_count":109,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class NeuralNet(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_classes):\n","        super(NeuralNet, self).__init__()\n","        self.l1 = nn.Linear(input_size, hidden_size)\n","        self.l2 = nn.Linear(hidden_size, hidden_size)\n","        self.l3 = nn.Linear(hidden_size, num_classes)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        out = self.l1(x)\n","        out = self.relu(out)\n","        out = self.l2(out)\n","        out = self.relu(out)\n","        out = self.l3(out)\n","        # no activation and no softmax\n","        return out"],"metadata":{"id":"u4Yxe6ynVmUW","executionInfo":{"status":"ok","timestamp":1665842406632,"user_tz":-330,"elapsed":77,"user":{"displayName":"Aditya Sharma","userId":"18274581938771633663"}}},"execution_count":110,"outputs":[]},{"cell_type":"code","source":["class ChatDataset(Dataset):\n","    def __init__(self):\n","        self.n_samples = len(X_train)\n","        self.x_data = X_train\n","        self.y_data = y_train\n","\n","    def __getitem__(self, idx):\n","        return self.x_data[idx], self.y_data[idx]\n","\n","    def __len__(self):\n","        return self.n_samples\n","\n","# hyperparameters\n","batch_size = 8\n","hidden_size = 8\n","output_size = len(tags)\n","input_size = len(X_train[0])\n","learning_rate = 0.001\n","num_epochs = 1000\n","\n","dataset = ChatDataset()\n","train_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, num_workers=2)"],"metadata":{"id":"Rm_v6q6ySQKe","executionInfo":{"status":"ok","timestamp":1665842406635,"user_tz":-330,"elapsed":77,"user":{"displayName":"Aditya Sharma","userId":"18274581938771633663"}}},"execution_count":111,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = NeuralNet(input_size, hidden_size, output_size).to(device)"],"metadata":{"id":"7PtzuLYFzuAU","executionInfo":{"status":"ok","timestamp":1665842406636,"user_tz":-330,"elapsed":75,"user":{"displayName":"Aditya Sharma","userId":"18274581938771633663"}}},"execution_count":112,"outputs":[]},{"cell_type":"code","source":["# loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"],"metadata":{"id":"KFzRjdwt2dcT","executionInfo":{"status":"ok","timestamp":1665842406638,"user_tz":-330,"elapsed":76,"user":{"displayName":"Aditya Sharma","userId":"18274581938771633663"}}},"execution_count":113,"outputs":[]},{"cell_type":"code","source":["# training loop\n","for epoch in range(num_epochs):\n","    for (words, labels) in train_loader:\n","        words = words.to(device)\n","        labels = labels.to(device)\n","\n","        # forward\n","        outputs = model(words)\n","        loss = criterion(outputs, labels)\n","\n","        # backward and optimizer step\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    if (epoch + 1) % 100 == 0:\n","        print(f\"epoch {epoch+1}/ {num_epochs}, loss = {loss.item():.4f}\")\n","\n","print(f\"final loss , loss = {loss.item():.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O9gAzit227n-","executionInfo":{"status":"ok","timestamp":1665842511953,"user_tz":-330,"elapsed":105385,"user":{"displayName":"Aditya Sharma","userId":"18274581938771633663"}},"outputId":"d2fc20ee-6d5e-4c07-9bac-87ece3ba6fc2"},"execution_count":114,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch 100/ 1000, loss = 1.0506\n","epoch 200/ 1000, loss = 0.0426\n","epoch 300/ 1000, loss = 0.0179\n","epoch 400/ 1000, loss = 0.0105\n","epoch 500/ 1000, loss = 0.0033\n","epoch 600/ 1000, loss = 0.0045\n","epoch 700/ 1000, loss = 0.0011\n","epoch 800/ 1000, loss = 0.0009\n","epoch 900/ 1000, loss = 0.0005\n","epoch 1000/ 1000, loss = 0.0008\n","final loss , loss = 0.0008\n"]}]},{"cell_type":"code","source":["data = {\n","    \"model_state\": model.state_dict(),\n","    \"input_size\": input_size,\n","    \"output_size\": output_size,\n","    \"hidden_size\": hidden_size,\n","    \"all_words\": all_words,\n","    \"tags\": tags\n","}\n","\n","FILE = \"data.pth\"\n","torch.save(data, FILE)\n","\n","print(f\"training complete. file saved to {FILE}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9AqbVAtY4F6k","executionInfo":{"status":"ok","timestamp":1665842511956,"user_tz":-330,"elapsed":60,"user":{"displayName":"Aditya Sharma","userId":"18274581938771633663"}},"outputId":"47c5a783-4df5-4676-b9ea-9666866197ee"},"execution_count":115,"outputs":[{"output_type":"stream","name":"stdout","text":["training complete. file saved to data.pth\n"]}]},{"cell_type":"markdown","source":["### implementation of Chat Bot"],"metadata":{"id":"Cdlyr_4I5o2_"}},{"cell_type":"code","source":["model.eval()    "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dYU7RiNS50it","executionInfo":{"status":"ok","timestamp":1665842511964,"user_tz":-330,"elapsed":54,"user":{"displayName":"Aditya Sharma","userId":"18274581938771633663"}},"outputId":"90559b60-1c49-4f73-f39a-d6bfdf1ae846"},"execution_count":116,"outputs":[{"output_type":"execute_result","data":{"text/plain":["NeuralNet(\n","  (l1): Linear(in_features=54, out_features=8, bias=True)\n","  (l2): Linear(in_features=8, out_features=8, bias=True)\n","  (l3): Linear(in_features=8, out_features=7, bias=True)\n","  (relu): ReLU()\n",")"]},"metadata":{},"execution_count":116}]},{"cell_type":"code","source":["import random\n","bot_name = \"Sam\"\n","print(\"Let's Chat! type 'quit' to exit\")\n","while True:\n","    sentence = input(\"You: \")\n","    if sentence == 'quit':\n","        break\n","    \n","    sentence = tokenize(sentence)\n","    X = bag_of_words(sentence, all_words)\n","    X = X.reshape(1, X.shape[0])\n","    X = torch.from_numpy(X)\n","\n","    output = model(X)\n","    _, predicted = torch.max(output, dim=1)\n","    tag = tags[predicted.item()]\n","\n","    probs = torch.softmax(output, dim=1)\n","    prob = probs[0][predicted.item()]\n","\n","    if prob.item() > 0.75:\n","        for intent in intents[\"intents\"]:\n","            if tag == intent[\"tag\"]:\n","                print(f\"{bot_name}: {random.choice(intent['responses'])}\")\n","    else:\n","        print(f\"{bot_name}: I do not understand...\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aLtwwuBV6-_Y","outputId":"1bb6cb2d-4674-406d-d312-b75a83ec2453"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Let's Chat! type 'quit' to exit\n","You: hi\n","Sam: Hey :-)\n","You: what do you sell?\n","Sam: We have coffee and tea\n","You: how long does it take to ship coffee?\n","Sam: Delivery takes 2-4 days\n","You: can you help me?\n","Sam: I do not understand...\n","You: bye\n","Sam: See you later, thanks for visiting\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"0xC_FKyy-cJj"},"execution_count":null,"outputs":[]}]}